{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['HF_HOME'] = '/scratch/' + str(open('../tokens/HPC_ACCOUNT_ID.txt', 'r').read())\n",
    "cache_dir = '/scratch/' + str(open('../tokens/HPC_ACCOUNT_ID.txt', 'r').read()) + '/cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c0ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"LeoZotos/immu_full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b94b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_api_key = \"\"\n",
    "with open(\"../tokens/HF_TOKEN.txt\", \"r\") as f:\n",
    "    hf_api_key = f.read().strip()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_docs(question_set, passages, batch_size=10000): \n",
    "    \"\"\"Retrieves the top k relevant documents for each question. Reduce batch_size if out-of-memory/process is killed\"\"\"\n",
    "    question_embs = torch.tensor(question_set['emb'], dtype=torch.bfloat16).to(device)\n",
    "    \n",
    "    all_scores = torch.tensor([[] for _ in range(len(question_set))], dtype=torch.bfloat16).to(device)\n",
    "    all_doc = [[] for _ in range(len(question_set))]\n",
    "\n",
    "    # Do retrieval. Reduce batch_size if out-of-memory\n",
    "    tmp_doc = []\n",
    "    tmp_emb = []\n",
    "    for passage_id, passage in enumerate(tqdm(passages)):\n",
    "        tmp_emb.append(passage['emb'])\n",
    "        tmp_doc.append({\"title\": passage['title'], \"text\": passage['text']})\n",
    "\n",
    "        if ((passage_id+1) % batch_size == 0) or (passage_id+1) == len(passages):\n",
    "            passage_emb = torch.tensor(tmp_emb, dtype=torch.bfloat16).to(device)\n",
    "            dot_scores = torch.mm(question_embs, passage_emb.T)\n",
    "            all_scores = torch.cat((all_scores, dot_scores), 1) \n",
    "            all_doc = [i + tmp_doc for i in all_doc]\n",
    "            all_scores, top_k_hits = torch.topk(all_scores, 20)\n",
    "            all_doc = [[all_doc[idx][j] for j in i] for idx, i in enumerate(top_k_hits)]\n",
    "\n",
    "            tmp_doc = []\n",
    "            tmp_emb = []\n",
    "\n",
    "    relevant_docs_combined = []\n",
    "    for i in range(len(all_doc)):\n",
    "        relevant_docs_combined.append([doc['title'] + \" \" + doc['text'] for doc in all_doc[i]])\n",
    "    \n",
    "    return relevant_docs_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_set = load_dataset(DATASET, split='train', token = hf_api_key, cache_dir=cache_dir)\n",
    "\n",
    "passages = load_dataset(\"Cohere/wikipedia-2023-11-embed-multilingual-v3\", 'simple', split=\"train\", cache_dir=cache_dir, token=hf_api_key)\n",
    "\n",
    "relevant_docs = retrieve_relevant_docs(question_set, passages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete relevant_docs_simple if \"relevant_docs_simple\" in question_set.column_names:\n",
    "if \"Relevant_Docs_Simple\" in question_set.column_names:\n",
    "    question_set = question_set.remove_columns(\"Relevant_Docs_Simple\")\n",
    "\n",
    "question_set = question_set.add_column(\"Relevant_Docs_Simple\", relevant_docs)\n",
    "\n",
    "# upload to hf\n",
    "question_set.push_to_hub(\n",
    "    repo_id=DATASET,\n",
    "    commit_message=\"Added relevant documents from Wiki Simple\",\n",
    "    token=hf_api_key,\n",
    "    private=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f5e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(question_set['Question_With_Options'][15])\n",
    "print(\"-----\")\n",
    "print(question_set['Relevant_Docs_Simple'][15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distractor_preference_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
